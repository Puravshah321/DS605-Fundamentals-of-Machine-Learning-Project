# ğŸ’¸ Money Laundering Detection â€“ FUSEX  
A Machine Learning Project on Imbalanced Classification, COâ‚‚ Efficiency, Sampling Strategy Evaluation & Model Optimization

---

## ğŸ‘¥ Collaborators  
**Team FUSEX**  
- Mannan Aggrawal (202518013)  
- Purav Shah (202518020)  
- Jay Salot (202518029)  
- Neel Shah (202518044)  

---

## ğŸ“‚ Dataset  
IBM Anti-Money Laundering (AML) Transactions Dataset  

ğŸ”— **Kaggle Link:**  
https://www.kaggle.com/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml/data?select=HI-Small_Trans.csv  

---

# ğŸ“Œ Project Overview  
Money laundering detection is a rare-event classification problem. Fraudulent transactions represent **<1%** of the dataset â†’ making it **extremely imbalanced**.

### Objectives:
- Build a scalable AML detection pipeline  
- Handle imbalance using different sampling techniques  
- Train, compare & tune multiple ML models  
- Reduce false negatives (Type-II errors)  
- Measure and compare **COâ‚‚ emissions**  
- Select the best model based on accuracy, recall & carbon-efficiency  

---

# ğŸ” Exploratory Data Analysis (EDA)

## **Univariate Analysis**
- Transaction amount highly **right-skewed**  
- Categorical features show **very high cardinality**  
- Fraud transactions had **higher mean values**  
- Multiple numeric features showed **class separation**  

## **Bivariate Analysis**
- Fraud correlated strongly with higher transaction amounts  
- Specific customer segments exhibited higher fraud rates  
- Correlation heatmap revealed strong numeric relationships  
- Bivariate trends favored **tree-based models** like LightGBM  

---

# âš–ï¸ Sampling Techniques Tried

## **1. Random Undersampling (RUS)**  
âœ“ Fastest  
âœ“ No synthetic noise  
âœ“ Works best with tree-based models  
âœ“ Best confusion matrix stability  
â†’ **Chosen as final method**

## **2. SMOTE (Numeric Only) + NN Categorical Matching + KMeans**
âœ— Introduced synthetic noise  
âœ— Very heavy computation  
âœ— Lower F1  

## **3. Full SMOTE**  
âœ— Unrealistic synthetic samples  
âœ— Overlapping boundaries  
âœ— Poor generalization  

---

# â­ Why We Selected Random Undersampling (RUS)

### âœ”ï¸ Highest recall + lowest false negatives  
### âœ”ï¸ Cleanest decision boundaries  
### âœ”ï¸ Best model performance with tree algorithms  
### âœ”ï¸ Lowest COâ‚‚ emissions  
### âœ”ï¸ Fastest training time  
### âœ”ï¸ Most stable confusion matrix  

---

# âš™ï¸ Model Training Pipeline

```python
X_train, X_test, y_train, y_test = train_test_split(
    X_s, y_s, test_size=0.3, random_state=42
)

ohe = Pipeline([
    ("Encoder", OneHotEncoder(drop="first", handle_unknown="ignore"))
])

transformer = ColumnTransformer([
    ("OneHot", ohe, cat)
])

model = Pipeline([
    ("Transformer", transformer),
    ("Estimator", XGBClassifier())
])

model.fit(X_train, y_train)
y_pred = model.predict(X_test)
```

---

# ğŸ¤– Models Trained

We trained 9 ML models:

- Logistic Regression  
- Decision Tree  
- Random Forest  
- GradientBoosting  
- AdaBoost  
- KNN  
- SVM  
- XGBoost  
- LightGBM  

---

# ğŸ“Š Performance Comparison Table (Before Tuning)

| Model | Accuracy | Precision | Recall | F1 | ROC-AUC | Type I Error | Type II Error |
|-------|----------|-----------|--------|------|----------|----------------|----------------|
| Logistic Regression | ~0.78 | Low | Moderate | Low | Moderate | High | High |
| Decision Tree | ~0.82 | Moderate | Moderate | Moderate | Moderate | Medium | Medium |
| Random Forest | ~0.86 | Good | Moderate | Good | Good | Medium | Medium |
| GradientBoosting | **0.88** | High | **0.97** | **0.90** | High | Low | Low |
| AdaBoost | ~0.84 | Moderate | Moderate | Moderate | Moderate | Medium | Medium |
| KNN | ~0.80 | Low | Low | Low | Low | High | High |
| SVM | 0.89 | **0.82** | **0.99** | **0.90** | High | Medium | **Very Low** |
| XGBoost | 0.87 | Good | High | High | High | Low | Low |
| LightGBM | **0.90** | **0.85** | **0.98** | **0.91** | **Highest** | **Lowest** | Very Low |

---

# ğŸ† Top 3 Models After Hyperparameter Tuning

| Rank | Model | F1 Score | Recall | Accuracy | COâ‚‚ Emissions | Notes |
|------|--------|----------|--------|----------|----------------|--------|
| **1** | **LightGBM (Tuned)** | **0.91** | **0.98** | **0.90** | â­ Lowest | Best overall performer |
| **2** | **GradientBoosting (Tuned)** | **0.90** | **0.97** | **0.88** | Moderate | Very stable & strong recall |
| **3** | **SVM (Linear Kernel, Tuned)** | **0.90** | **0.99** | **0.89** | â— Highest | Excellent recall but too costly |

---

# ğŸ“¸ Confusion Matrices (Tuned Models)

### **SVM â€“ Tuned**
<img width="534" src="https://github.com/user-attachments/assets/c31209d1-87ce-4848-8872-4f5237186cfc">

### **GradientBoosting â€“ Tuned**
<img width="534" src="https://github.com/user-attachments/assets/072d0963-afb1-4b48-9cb7-845ca549791e">

### **LightGBM â€“ Tuned**
<img width="534" src="https://github.com/user-attachments/assets/02704b14-c089-4a62-9b34-a4364a4eb16a">

---

# ğŸŒ± COâ‚‚ Emission Comparison

<img width="684" src="https://github.com/user-attachments/assets/b77c99c3-8640-4ad6-95bc-89e7e5689960">

### Insights:
- **LightGBM = Lowest COâ‚‚**  
- GradientBoosting moderate  
- **SVM = Highest COâ‚‚** â†’ Not ideal for production  

---

# ğŸ”§ Threshold Tuning (Reducing FN)

### Recommended Threshold: **0.38**

### Confusion Matrix at 0.38:
```
[[1257  329]
 [  36 1485]]
```

### Key Benefits:
- FN reduced from **45 â†’ 36**  
- Huge recall improvement  
- Slight FP increase acceptable in AML  

---

# ğŸ”¥ Hyperparameter Tuning

### Example (SVM):
```
Best Params:
{'clf__kernel': 'linear', 'clf__C': 0.1}
```

Tuning improved:
- F1 Score  
- Recall  
- Model stability  

---

# ğŸ§© Difficulties We Faced & Solutions

### 1ï¸âƒ£ Extreme Imbalance  
âœ… Solution: Switched from SMOTE â†’ RUS  

### 2ï¸âƒ£ Categorical SMOTE Complexity  
âŒ Too slow, too noisy â†’ Dropped  

### 3ï¸âƒ£ High COâ‚‚ Usage in SVM  
âŒ Not suitable for production  

### 4ï¸âƒ£ Threshold Optimization  
âœ… Full sweep performed â†’ Found 0.38  

### 5ï¸âƒ£ High Cardinality  
âœ… OneHotEncoder(drop="first") used  

---

# ğŸ†• Novelty of Our Approach

- **COâ‚‚-aware ML model selection**  
- Custom **Safe-SMOTE** implementation  
- Full **threshold sweep** for minimizing Type-II errors  
- Unified, reusable ML pipeline  

---

# ğŸ Final Conclusion

### ğŸŸ© **Best Sampling Method â†’ Random Undersampling (RUS)**  
### ğŸŸ© **Best Overall Model â†’ LightGBM (91% F1, 98% Recall, Lowest COâ‚‚)**  
### ğŸŸ¨ **Runner-Up â†’ GradientBoosting (Strong recall, stable performance)**  
### ğŸŸ§ **High Recall but Not Selected â†’ SVM (Too high COâ‚‚ emission)**  
### âŒ **Avoid â†’ SMOTE + KMeans (Noisy, slow, bad real-world stability)**  

**LightGBM was chosen as the final model because it delivered:**  
âœ“ Best F1 Score (0.91)  
âœ“ Extremely high recall (0.98)  
âœ“ Lowest false negatives  
âœ“ Lowest COâ‚‚ emissions  
âœ“ Fastest inference â†’ suitable for real-time AML systems  

---
